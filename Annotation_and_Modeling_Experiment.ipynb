{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# This code makes plots appear inline in this document rather than in a new window\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5, 4) # set default size of plots\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line imports the Pandas Library\n",
    "import pandas as pd\n",
    "\n",
    "# This line imports defaultdict() from collections\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data (index, text, label) in the variable \"data\"\n",
    "df = pd.read_excel('Data_file.xlsx', index_col=0, header=0, usecols=\"A:B, F\", names = [\"Index\", \"Text\", \"Label\"], sheet_name=\"Data\")\n",
    "\n",
    "# Correcting the \"NA\" labels, since Pandas imports them as NaN objects of type float\n",
    "for i in range(len(df.Label)):\n",
    "    if type(df.Label[i])==float:\n",
    "        df.Label[i] = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels that will be used\n",
    "MOVIE_LABEL = \"MOV\" #Any content related to movies\n",
    "TECHNOLOGY_LABEL = \"TEC\" #Any content related to technology: websites, NLP, text-to-speech, and more\n",
    "COLLEGE_LABEL = \"COL\" #Anything related to UMass Amherst/College Life\n",
    "NOT_APPLICABLE_LABEL = \"NA\" #Not Applicable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tokenization, I am using the default tokenizer that is provided inside the TfidfVectorizer by SkLearn. I am using its default tokenizer because it splits documents on white-spaces so splits the documents into words, then it separates hyphenated words like \"prize-winning\" and \"half-asleep\", and it splits the document at any punctuation. Since we have a small data set each word concatenated by punctuation might hold its own value for labeling. For example, my dataset contains words like \"pre-trained\" and \"Burton-y\" where the word 'trained' by itself may tell us that the text is probably about technology and 'Burton' might indicate it probably about a movie. To take into consideration 2 or more words (concatenated by punctuation) like \"Text-to-speech\" that might hold value, I will use n-gram tokenization in the range (1, 4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, analyzer='word', \n",
    "                             stop_words= 'english',ngram_range=(1,2), min_df=2, max_df=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For preprocessing all the words are lowercased: it will allow instances of 'Capitalized' (words) at the beginning of a sentence to match with a query of 'capitalized' (words). Further, I remove tokens that are stop words (English), since stop words almost always exist in all labels and are redundant. Words that are unique to just one document as removed using the parameter min_df = 2, since a word that is unique to a document will probably not help with classification. Words in more than 150 documents are removed as well since if a word exists in more than 150 documents than the chances of the word being unique to a label are less since the highest document frequency for a label (NA) is 96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = (vectorizer.fit_transform(df['Text'])).toarray()\n",
    "\n",
    "words = vectorizer.get_feature_names()\n",
    "vocab = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 Tokens after sorting: ['20', '200', 'actually', 'advice', 'ago', 'algebra', 'amazing', 'answer', 'api', 'ask', 'best', 'better', 'bit', 'book', 'called', 'calls', 'campus', 'class', 'classes', 'cola']\n"
     ]
    }
   ],
   "source": [
    "print(\"First 20 Tokens after sorting:\", words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf \n",
    "y = np.zeros(250)\n",
    "\n",
    "for i in range(len(df.Label)):\n",
    "    if df.Label[i]==MOVIE_LABEL:\n",
    "        y[i] = 1.0\n",
    "    elif df.Label[i]==TECHNOLOGY_LABEL:\n",
    "        y[i] = 2.0\n",
    "    elif df.Label[i]==COLLEGE_LABEL:\n",
    "        y[i] = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = (LogisticRegression(verbose=1, solver='lbfgs', penalty='l2', max_iter=500).fit(x, y))\n",
    "\n",
    "accuracy_scores = cross_val_score(model, x, y, cv=5)\n",
    "\n",
    "sum_accuracy_scores = 0\n",
    "for num in accuracy_scores:\n",
    "    sum_accuracy_scores+=num\n",
    "\n",
    "accuracy = sum_accuracy_scores/len(accuracy_scores)\n",
    "print(\"Overall Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify=df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = model.predict_proba(x_test)\n",
    "\n",
    "y_predictions = []\n",
    "for i in range(len(confidence)):\n",
    "    max_index  = -1\n",
    "    max_value = -1\n",
    "    for j in range(len(confidence[i])):\n",
    "        if confidence[i][j]>max_value:\n",
    "            max_index = j \n",
    "            max_value = confidence[i][j]\n",
    "    \n",
    "    y_predictions.append(max_index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NA       1.00      0.59      0.75        32\n",
      "         MOV       0.67      1.00      0.80        10\n",
      "         TEC       0.44      1.00      0.62         4\n",
      "         COL       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.67      0.90      0.72        50\n",
      "weighted avg       0.85      0.74      0.74        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names=[NOT_APPLICABLE_LABEL, MOVIE_LABEL, TECHNOLOGY_LABEL, COLLEGE_LABEL]\n",
    "print(classification_report(y_predictions, y_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = tfidf\n",
    "word_weights = {MOVIE_LABEL: defaultdict(),\n",
    "             COLLEGE_LABEL: defaultdict(),\n",
    "             TECHNOLOGY_LABEL: defaultdict(),\n",
    "             NOT_APPLICABLE_LABEL: defaultdict()}\n",
    "\n",
    "for i in range(len(bow)):\n",
    "    row = bow[i]\n",
    "    for j in range(len(row)):\n",
    "        word_weight = row[j]\n",
    "        word = words[j]\n",
    "        if word not in word_weights[df.Label[i]]:\n",
    "            word_weights[df.Label[i]][word] = word_weight\n",
    "        else:\n",
    "            word_weights[df.Label[i]][word] += word_weight\n",
    "\n",
    "for label in word_weights:\n",
    "    word_weights[label] = sorted(word_weights[label].items(),key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ten(label, label_dict):\n",
    "    print(\"Top-10 highest weighted words for\", label)\n",
    "    print()\n",
    "    for i in range(0, 10):\n",
    "        print(f\"{i+1} Word: {label_dict[i][0]}, Weight: {label_dict[i][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 highest weighted words for MOV\n",
      "\n",
      "1 Word: movie, Weight: 5.032352423717666\n",
      "2 Word: movies, Weight: 4.516040889968569\n",
      "3 Word: great, Weight: 4.0\n",
      "4 Word: good, Weight: 2.867553228266578\n",
      "5 Word: remake, Weight: 2.32902111955974\n",
      "6 Word: watching, Weight: 2.146617289968964\n",
      "7 Word: film, Weight: 2.1283315480618112\n",
      "8 Word: just, Weight: 2.1168833703103616\n",
      "9 Word: way, Weight: 2.0925094279870295\n",
      "10 Word: ve, Weight: 1.8664992184525673\n"
     ]
    }
   ],
   "source": [
    "top_ten(MOVIE_LABEL, word_weights[MOVIE_LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 highest weighted words for COL\n",
      "\n",
      "1 Word: umass, Weight: 3.831318937143369\n",
      "2 Word: major, Weight: 2.6957913571321424\n",
      "3 Word: frats, Weight: 2.354513921946645\n",
      "4 Word: class, Weight: 1.918284212689718\n",
      "5 Word: cs, Weight: 1.8805116547216971\n",
      "6 Word: student, Weight: 1.7735471301073815\n",
      "7 Word: classes, Weight: 1.72487490286209\n",
      "8 Word: 200, Weight: 1.530413386131268\n",
      "9 Word: coming, Weight: 1.5087539783908794\n",
      "10 Word: getting, Weight: 1.4124444450940081\n"
     ]
    }
   ],
   "source": [
    "top_ten(COLLEGE_LABEL, word_weights[COLLEGE_LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 highest weighted words for TEC\n",
      "\n",
      "1 Word: ve, Weight: 2.612578951359384\n",
      "2 Word: tokens, Weight: 2.0\n",
      "3 Word: nlp, Weight: 1.6633090166873892\n",
      "4 Word: cola, Weight: 1.5983009867135576\n",
      "5 Word: real, Weight: 1.5862947002085048\n",
      "6 Word: faster, Weight: 1.5773502691896257\n",
      "7 Word: tts, Weight: 1.5538077857179051\n",
      "8 Word: word, Weight: 1.5495284403793137\n",
      "9 Word: data, Weight: 1.4345414181697302\n",
      "10 Word: python, Weight: 1.2844570503761734\n"
     ]
    }
   ],
   "source": [
    "top_ten(TECHNOLOGY_LABEL, word_weights[TECHNOLOGY_LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 highest weighted words for NA\n",
      "\n",
      "1 Word: like, Weight: 4.981282367169192\n",
      "2 Word: just, Weight: 3.915425096018624\n",
      "3 Word: thanks, Weight: 3.652315376953827\n",
      "4 Word: heard, Weight: 2.816410653164552\n",
      "5 Word: good, Weight: 2.689898793878429\n",
      "6 Word: pretty, Weight: 2.5601707836895775\n",
      "7 Word: maybe, Weight: 2.5480692476890043\n",
      "8 Word: does, Weight: 2.095094359716256\n",
      "9 Word: time, Weight: 2.095044042684684\n",
      "10 Word: writing, Weight: 1.9237925173309651\n"
     ]
    }
   ],
   "source": [
    "top_ten(NOT_APPLICABLE_LABEL, word_weights[NOT_APPLICABLE_LABEL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first three categories, the top 10 weighted words make a lot of sense. For the first three categories, it is clear as to why the top 10 words have the highest weights since they are literally/directly related to the label and so were present in most of the text (under that label). However, the top 10 words for the NA (not applicable) category don't make much sense (could be because it is a general 4th category). I think this is also a reason why the accuracy was so low because words like, heard, and good can easily be present when someone is talking about a movie or a class. These weights indicate the strong relation of the labels with their top 10 highest weighted words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
